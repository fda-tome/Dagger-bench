#!/bin/bash
#PBS -l select=8:system=aurora
#PBS -l place=scatter
#PBS -l walltime=02:00:00
#PBS -q prod
#PBS -A Aurora_deployment
#PBS -N dagger_barnes_strong_scaling
#PBS -j oe

# Aurora Barnes-Hut Strong Scaling Study
# Fixed problem size, increasing processor count

module use /soft/modulefiles
module load frameworks/2024.1
module load julia

cd $PBS_O_WORKDIR

# Setup
BENCHMARK_DIR="${PBS_O_WORKDIR}/benchmarks/comparison"
RESULTS_DIR="${PBS_O_WORKDIR}/results/aurora_$(date +%Y%m%d_%H%M%S)"
mkdir -p $RESULTS_DIR

cd $BENCHMARK_DIR

# Setup MPI for Dagger distributed execution
export JULIA_MPI_BINARY=system
export JULIA_NUM_THREADS=104   # Full node threading

# Dagger will auto-discover processors via MPI
cat $PBS_NODEFILE | sort -u > hostfile
NUM_NODES=$(cat $PBS_NODEFILE | sort -u | wc -l)

# Fixed problem size for strong scaling
export BARNES_N=2000000        # 2 million bodies
export BARNES_THETA=0.5
export BENCH_RUNS=5

echo "========================================"
echo "Aurora Strong Scaling Study - Barnes-Hut"
echo "========================================"
echo "Problem size: N=${BARNES_N}"
echo "Theta: ${BARNES_THETA}"
echo "Runs per configuration: ${BENCH_RUNS}"
echo "Job ID: ${PBS_JOBID}"
echo "Nodes allocated: 8"
echo "========================================"

# Test configurations: 1, 2, 4, 8 nodes
for NODES in 1 2 4 8; do
    NPROCS=$((NODES * 104))  # 104 cores per node
    
    echo ""
    echo ">>> Testing with ${NODES} nodes (${NPROCS} cores)..."
    echo ""
    
    # Create node-specific machine file for this test
    head -n ${NODES} hostfile > hostfile_${NODES}
    
    # Run with Dagger using MPI backend
    # Dagger auto-discovers the ${NPROCS} processors
    mpiexec -n ${NPROCS} \
            -ppn 104 \
            --hostfile hostfile_${NODES} \
            julia --project=../../demos/advanced/barnes \
                  -t 1 \
                  barnes_benchmark_mpi.jl \
            2>&1 | tee ${RESULTS_DIR}/barnes_${NODES}nodes_${NPROCS}cores.log
    
    # Copy CSV results
    cp barnes_benchmark_*.csv ${RESULTS_DIR}/ 2>/dev/null || true
    
    echo "Completed ${NODES} nodes"
    sleep 5  # Brief pause between runs
done

# Generate summary
echo ""
echo "========================================"
echo "Strong Scaling Study Complete"
echo "========================================"
echo "Results saved to: ${RESULTS_DIR}"
echo ""
echo "Expected speedup analysis:"
echo "  1 node  (104 cores):   baseline"
echo "  2 nodes (208 cores):   ~1.8x speedup"
echo "  4 nodes (416 cores):   ~3.5x speedup"
echo "  8 nodes (832 cores):   ~6-7x speedup"
echo "========================================"

# Clean up
rm -f hostfile_* barnes_benchmark_*.csv
